# Exploring Bias in Language Model Embeddings (Volunteer Research Work)

Some work I did on word embeddings in LLMs to detect bias. Note this repository was cloned from https://github.com/wolferobert3/gender_bias_swe_aies2022 and built off of it.

- Used ChatGPT's API, Cohere API, BGE M3's Flag Model, and Microsoft E5 to gather LLM embeddings to perform analysis on.
- Used the top 100k words in the English language to perform analysis on the bias of these words using SC-WEATs primarily on gender (Man and Woman). Calculated an effect size to see how prevalent the bias is in these words.
- Used big tech words to see how they correlate between gender and expanded the functions to take different types of words.
- Generated various charts and graphs denoting bias such as effect size.
- Expands on the paper Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency, Syntax, and Semantics (https://dl.acm.org/doi/pdf/10.1145/3514094.3534162) and “I’m sorry to hear that”: Finding New Biases in Language Models with a Holistic Descriptor Dataset (https://aclanthology.org/2022.emnlp-main.625.pdf)

![image](https://github.com/user-attachments/assets/0456d917-1bb1-44ce-81b2-b7bfd6ba0da7)

![image](https://github.com/user-attachments/assets/324f1654-fcac-4788-a72d-44535ad384f4)

![image](https://github.com/user-attachments/assets/a03ffbf2-55b7-4b45-bf9d-3d77794fc2b2)


